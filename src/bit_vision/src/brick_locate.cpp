///////////////////////////////////////////////////////////////////////////////
// File generated by HDevelop for HALCON/C++ Version 18.05
///////////////////////////////////////////////////////////////////////////////



#ifndef __APPLE__
#  include "HalconCpp.h"
#  include "HDevThread.h"
#  if defined(__linux__) && !defined(__arm__) && !defined(NO_EXPORT_APP_MAIN)
#    include <X11/Xlib.h>
#  endif
#else
#  ifndef HC_LARGE_IMAGES
#    include <HALCONCpp/HalconCpp.h>
#    include <HALCONCpp/HDevThread.h>
#  else
#    include <HALCONCppxl/HalconCpp.h>
#    include <HALCONCppxl/HDevThread.h>
#  endif
#  include <stdio.h>
#  include <HALCON/HpThread.h>
#  include <CoreFoundation/CFRunLoop.h>
#endif

#include <ros/ros.h>
#include <sensor_msgs/Image.h>
#include "HalconCpp.h"
#include <string>
#include <iostream>
#include <stdlib.h>
#include "ros/ros.h"
#include <sstream>
#include <math.h>
#include "halcon_image.h"
#include "sensor_msgs/Image.h"
#include "std_msgs/Empty.h"
#include "tf/transform_broadcaster.h"
#include "bit_vision/BrickLocate.h"


using namespace std;
using namespace HalconCpp;

//定义全局变量 用于三维坐标的传递
static HTuple Xl,Yl,Xr,Yr;    // 左右相机定位目标的像素位置
static HTuple brick_color_L, brick_color_R;    // 左右相机识别的颜色信息
//定义传递三维坐标的全局变量
static HTuple Brick_X,Brick_Y,Brick_Z;

// Procedure declarations 
// Local procedures 
void classify (HObject ho_Regions, HTuple hv_MLPHandle, HTuple *hv_Classes);
// Short Description: compute texture features on multiple pyramid levels 
void gen_features (HObject ho_Image, HTuple *hv_FeatureVector);
// Short Description: compute various texture features and append them to input feature vector 
void gen_sobel_features (HObject ho_Image, HTuple hv_Features, HTuple *hv_FeaturesExtended);
void get_features (HObject ho_Region, HTuple *hv_Features);
void segment (HObject ho_Image, HObject *ho_Regions);

// Procedures 
// Local procedures 
void classify (HObject ho_Regions, HTuple hv_MLPHandle, HTuple *hv_Classes)
{

  // Local iconic variables
  HObject  ho_Region;

  // Local control variables
  HTuple  hv_Number, hv_J, hv_Features, hv_Class;
  HTuple  hv_Confidence;

  CountObj(ho_Regions, &hv_Number);
  (*hv_Classes) = HTuple();
  {
  HTuple end_val2 = hv_Number;
  HTuple step_val2 = 1;
  for (hv_J=1; hv_J.Continue(end_val2, step_val2); hv_J += step_val2)
  {
    SelectObj(ho_Regions, &ho_Region, hv_J);
    get_features(ho_Region, &hv_Features);
    ClassifyClassMlp(hv_MLPHandle, hv_Features, 1, &hv_Class, &hv_Confidence);
    (*hv_Classes) = (*hv_Classes).TupleConcat(hv_Class);
  }
  }
  return;
}

// Short Description: compute texture features on multiple pyramid levels 
void gen_features (HObject ho_Image, HTuple *hv_FeatureVector)
{

  // Local iconic variables
  HObject  ho_Zoomed1;

  (*hv_FeatureVector) = HTuple();
  //Compute features.
  gen_sobel_features(ho_Image, (*hv_FeatureVector), &(*hv_FeatureVector));
  //Downscale the image (image pyramid) and compute features.
  ZoomImageFactor(ho_Image, &ho_Zoomed1, 0.5, 0.5, "constant");
  gen_sobel_features(ho_Zoomed1, (*hv_FeatureVector), &(*hv_FeatureVector));
  //Uncomment lines to use further pyramid levels:
  //zoom_image_factor (Zoomed1, Zoomed2, 0.5, 0.5, 'constant')
  //gen_sobel_features (Zoomed2, FeatureVector, FeatureVector)
  //zoom_image_factor (Zoomed2, Zoomed3, 0.5, 0.5, 'constant')
  //gen_sobel_features (Zoomed3, FeatureVector, FeatureVector)
  //zoom_image_factor (Zoomed3, Zoomed4, 0.5, 0.5, 'constant')
  //gen_sobel_features (Zoomed4, FeatureVector, FeatureVector)
  (*hv_FeatureVector) = (*hv_FeatureVector).TupleReal();
  return;
}

// Short Description: compute various texture features and append them to input feature vector 
void gen_sobel_features (HObject ho_Image, HTuple hv_Features, HTuple *hv_FeaturesExtended)
{

  // Local iconic variables
  HObject  ho_EdgeAmplitude;

  // Local control variables
  HTuple  hv_Energy, hv_Correlation, hv_Homogeneity;
  HTuple  hv_Contrast, hv_AbsoluteHistoEdgeAmplitude;

  //Coocurrence matrix for 90 deg:
  CoocFeatureImage(ho_Image, ho_Image, 6, 90, &hv_Energy, &hv_Correlation, &hv_Homogeneity, 
      &hv_Contrast);
  //Absolute histogram of edge amplitudes:
  SobelAmp(ho_Image, &ho_EdgeAmplitude, "sum_abs", 3);
  GrayHistoAbs(ho_EdgeAmplitude, ho_EdgeAmplitude, 8, &hv_AbsoluteHistoEdgeAmplitude);
  //
  //You could of course compute more features:
  //Entropy and anisotropy:
  //entropy_gray (Image, Image, Entropy, Anisotropy)
  //Absolute histogram of gray values:
  //gray_histo_abs (Image, Image, 8, AbsoluteHistoImage)
  //Add features to feature vector:
  (*hv_FeaturesExtended).Clear();
  (*hv_FeaturesExtended).Append(hv_Features);
  (*hv_FeaturesExtended).Append(hv_Energy);
  (*hv_FeaturesExtended).Append(hv_Correlation);
  (*hv_FeaturesExtended).Append(hv_Homogeneity);
  (*hv_FeaturesExtended).Append(hv_Contrast);
  (*hv_FeaturesExtended) = (*hv_FeaturesExtended).TupleConcat(hv_AbsoluteHistoEdgeAmplitude);
  //Activate the following lines to add the additional features you activated:
  //FeaturesExtended := [FeaturesExtended,Entropy,Anisotropy]
  //FeaturesExtended := [FeaturesExtended,AbsoluteHistoImage]
  return;
}

void get_features (HObject ho_Region, HTuple *hv_Features)
{

  // Local iconic variables
  HObject  ho_SingleRegion;

  // Local control variables
  HTuple  hv_Circularity, hv_Distance, hv_Sigma;
  HTuple  hv_Roundness, hv_Sides, hv_PSI1, hv_PSI2, hv_PSI3;
  HTuple  hv_PSI4;

  SelectObj(ho_Region, &ho_SingleRegion, 1);
  Circularity(ho_SingleRegion, &hv_Circularity);
  Roundness(ho_SingleRegion, &hv_Distance, &hv_Sigma, &hv_Roundness, &hv_Sides);
  MomentsRegionCentralInvar(ho_SingleRegion, &hv_PSI1, &hv_PSI2, &hv_PSI3, &hv_PSI4);
  (*hv_Features).Clear();
  (*hv_Features).Append(hv_Circularity);
  (*hv_Features).Append(hv_Roundness);
  (*hv_Features).Append(hv_PSI1);
  (*hv_Features).Append(hv_PSI2);
  (*hv_Features).Append(hv_PSI3);
  (*hv_Features).Append(hv_PSI4);
  return;
}

void segment (HObject ho_Image, HObject *ho_Regions)
{

  // Local iconic variables
  HObject  ho_Region, ho_ConnectedRegions;

  // Local control variables
  HTuple  hv_UsedThreshold;

  BinaryThreshold(ho_Image, &ho_Region, "max_separability", "dark", &hv_UsedThreshold);
  Connection(ho_Region, &ho_ConnectedRegions);
  FillUp(ho_ConnectedRegions, &(*ho_Regions));
  return;
}


/***************************************************************************
   自己的程序开始
***************************************************************************/


// Main procedure 
void actionL(HObject Image)
{
  // Local iconic variables
  HObject  ho_ImageL, ho_ClassRegions, ho_ImageR;
  HObject  ho_ClassRegions2, ho_ClassRed, ho_ClassGreen, ho_ClassBLue;
  HObject  ho_ConnectedRegions1, ho_ConnectedRegions2, ho_ConnectedRegions3;
  HObject  ho_ObjectSelectedRed, ho_ObjectSelectedGreen, ho_ObjectSelectedBlue;
  HObject  ho_ClassRed2, ho_ClassGreen2, ho_ClassBLue2, ho_ConnectedRegions1_2;
  HObject  ho_ConnectedRegions2_2, ho_ConnectedRegions3_2;
  HObject  ho_ObjectSelectedRed_2, ho_ObjectSelectedGreen_2;
  HObject  ho_ObjectSelectedBlue_2;

  // Local control variables
  HTuple  hv_pathFile, hv_MLPHandle, hv_Area1, hv_Row1;
  HTuple  hv_Column1, hv_Indices, hv_num, hv_Area_1, hv_Row_1;
  HTuple  hv_Column_1, hv_Area2, hv_Row2, hv_Column2, hv_Area_2;
  HTuple  hv_Row_2, hv_Column_2, hv_Area3, hv_Row3, hv_Column3;
  HTuple  hv_Area_3, hv_Row_3, hv_Column_3, hv_areas, hv_rows;
  HTuple  hv_columns, hv_index, hv_class, hv_row_L, hv_column_L;
  HTuple  hv_Area1_2, hv_Row1_2, hv_Column1_2, hv_Indices_2;
  HTuple  hv_num2, hv_Area_1_2, hv_Row_1_2, hv_Column_1_2;
  HTuple  hv_Area_2_2, hv_Row_2_2, hv_Column_2_2, hv_Area3_2;
  HTuple  hv_Row3_2, hv_Column3_2, hv_Area_3_2, hv_Row_3_2;
  HTuple  hv_Column_3_2, hv_areas_2, hv_rows_2, hv_columns_2;
  HTuple  hv_index_2, hv_row_R, hv_column_R;

  //读入训练好的分割mlp模型
  hv_pathFile = "./src/bit_vision/model/box_segment_mlp.mlp";
  ReadClassMlp(hv_pathFile, &hv_MLPHandle);

  ClassifyImageClassMlp(Image, &ho_ClassRegions, hv_MLPHandle, 0.9);

  SelectObj(ho_ClassRegions, &ho_ClassRed, 1);
  SelectObj(ho_ClassRegions, &ho_ClassGreen, 2);
  SelectObj(ho_ClassRegions, &ho_ClassBLue, 3);

  Connection(ho_ClassRed, &ho_ConnectedRegions1);
  Connection(ho_ClassGreen, &ho_ConnectedRegions2);
  Connection(ho_ClassBLue, &ho_ConnectedRegions3);

  AreaCenter(ho_ConnectedRegions1, &hv_Area1, &hv_Row1, &hv_Column1);
  TupleSortIndex(hv_Area1, &hv_Indices);
  hv_num = hv_Indices.TupleLength();
  SelectObj(ho_ConnectedRegions1, &ho_ObjectSelectedRed, HTuple(hv_Indices[hv_num-1])+1);
  AreaCenter(ho_ObjectSelectedRed, &hv_Area_1, &hv_Row_1, &hv_Column_1);

  AreaCenter(ho_ConnectedRegions2, &hv_Area2, &hv_Row2, &hv_Column2);
  TupleSortIndex(hv_Area2, &hv_Indices);
  hv_num = hv_Indices.TupleLength();
  SelectObj(ho_ConnectedRegions2, &ho_ObjectSelectedGreen, HTuple(hv_Indices[hv_num-1])+1);
  AreaCenter(ho_ObjectSelectedGreen, &hv_Area_2, &hv_Row_2, &hv_Column_2);

  AreaCenter(ho_ConnectedRegions3, &hv_Area3, &hv_Row3, &hv_Column3);
  TupleSortIndex(hv_Area3, &hv_Indices);
  hv_num = hv_Indices.TupleLength();
  SelectObj(ho_ConnectedRegions3, &ho_ObjectSelectedBlue, HTuple(hv_Indices[hv_num-1])+1);
  AreaCenter(ho_ObjectSelectedBlue, &hv_Area_3, &hv_Row_3, &hv_Column_3);

  //比较3种region的面积 面积最大的作为分类结果
  hv_areas.Clear();
  hv_areas.Append(hv_Area_1);
  hv_areas.Append(hv_Area_2);
  hv_areas.Append(hv_Area_3);
  //提取面积最大的区域对应的坐标
  hv_rows.Clear();
  hv_rows.Append(hv_Row_1);
  hv_rows.Append(hv_Row_2);
  hv_rows.Append(hv_Row_3);
  hv_columns.Clear();
  hv_columns.Append(hv_Column_1);
  hv_columns.Append(hv_Column_2);
  hv_columns.Append(hv_Column_3);

  TupleSortIndex(hv_areas, &hv_Indices);
  hv_num = hv_Indices.TupleLength();
  hv_index = HTuple(hv_Indices[hv_num-1]);

  if (0 != (hv_index==0))
  {
    hv_class = "red";
  }
  else if (0 != (hv_index==1))
  {
    hv_class = "green";
  }
  else if (0 != (hv_index==2))
  {
    hv_class = "blue";
  }

  brick_color_L = hv_class;

  hv_row_L = HTuple(hv_rows[hv_index]);
  hv_column_L = HTuple(hv_columns[hv_index]);

  Xl=hv_row_L;
  Yl=hv_column_L;
  
}

void actionR(HObject Image)
{

  // Local iconic variables
  HObject  ho_ImageL, ho_ClassRegions, ho_ImageR;
  HObject  ho_ClassRegions2, ho_ClassRed, ho_ClassGreen, ho_ClassBLue;
  HObject  ho_ConnectedRegions1, ho_ConnectedRegions2, ho_ConnectedRegions3;
  HObject  ho_ObjectSelectedRed, ho_ObjectSelectedGreen, ho_ObjectSelectedBlue;
  HObject  ho_ClassRed2, ho_ClassGreen2, ho_ClassBLue2, ho_ConnectedRegions1_2;
  HObject  ho_ConnectedRegions2_2, ho_ConnectedRegions3_2;
  HObject  ho_ObjectSelectedRed_2, ho_ObjectSelectedGreen_2;
  HObject  ho_ObjectSelectedBlue_2;

  // Local control variables
  HTuple  hv_pathFile, hv_MLPHandle, hv_Area1, hv_Row1;
  HTuple  hv_Column1, hv_Indices, hv_num, hv_Area_1, hv_Row_1;
  HTuple  hv_Column_1, hv_Area2, hv_Row2, hv_Column2, hv_Area_2;
  HTuple  hv_Row_2, hv_Column_2, hv_Area3, hv_Row3, hv_Column3;
  HTuple  hv_Area_3, hv_Row_3, hv_Column_3, hv_areas, hv_rows;
  HTuple  hv_columns, hv_index, hv_class, hv_row_L, hv_column_L;
  HTuple  hv_Area1_2, hv_Row1_2, hv_Column1_2, hv_Indices_2;
  HTuple  hv_num2, hv_Area_1_2, hv_Row_1_2, hv_Column_1_2;
  HTuple  hv_Area_2_2, hv_Row_2_2, hv_Column_2_2, hv_Area3_2;
  HTuple  hv_Row3_2, hv_Column3_2, hv_Area_3_2, hv_Row_3_2;
  HTuple  hv_Column_3_2, hv_areas_2, hv_rows_2, hv_columns_2;
  HTuple  hv_index_2, hv_row_R, hv_column_R;

  //读入训练好的分割mlp模型
  hv_pathFile = "./src/bit_vision/model/box_segment_mlp.mlp";
  ReadClassMlp(hv_pathFile, &hv_MLPHandle);
  
  ClassifyImageClassMlp(Image, &ho_ClassRegions, hv_MLPHandle, 0.9);
  

  SelectObj(ho_ClassRegions, &ho_ClassRed, 1);
  SelectObj(ho_ClassRegions, &ho_ClassGreen, 2);
  SelectObj(ho_ClassRegions, &ho_ClassBLue, 3);

  Connection(ho_ClassRed, &ho_ConnectedRegions1);
  Connection(ho_ClassGreen, &ho_ConnectedRegions2);
  Connection(ho_ClassBLue, &ho_ConnectedRegions3);

  AreaCenter(ho_ConnectedRegions1, &hv_Area1, &hv_Row1, &hv_Column1);
  TupleSortIndex(hv_Area1, &hv_Indices);
  hv_num = hv_Indices.TupleLength();
  SelectObj(ho_ConnectedRegions1, &ho_ObjectSelectedRed, HTuple(hv_Indices[hv_num-1])+1);
  AreaCenter(ho_ObjectSelectedRed, &hv_Area_1, &hv_Row_1, &hv_Column_1);

  AreaCenter(ho_ConnectedRegions2, &hv_Area2, &hv_Row2, &hv_Column2);
  TupleSortIndex(hv_Area2, &hv_Indices);
  hv_num = hv_Indices.TupleLength();
  SelectObj(ho_ConnectedRegions2, &ho_ObjectSelectedGreen, HTuple(hv_Indices[hv_num-1])+1);
  AreaCenter(ho_ObjectSelectedGreen, &hv_Area_2, &hv_Row_2, &hv_Column_2);

  AreaCenter(ho_ConnectedRegions3, &hv_Area3, &hv_Row3, &hv_Column3);
  TupleSortIndex(hv_Area3, &hv_Indices);
  hv_num = hv_Indices.TupleLength();
  SelectObj(ho_ConnectedRegions3, &ho_ObjectSelectedBlue, HTuple(hv_Indices[hv_num-1])+1);
  AreaCenter(ho_ObjectSelectedBlue, &hv_Area_3, &hv_Row_3, &hv_Column_3);

  //比较3种region的面积 面积最大的作为分类结果
  hv_areas.Clear();
  hv_areas.Append(hv_Area_1);
  hv_areas.Append(hv_Area_2);
  hv_areas.Append(hv_Area_3);
  //提取面积最大的区域对应的坐标
  hv_rows.Clear();
  hv_rows.Append(hv_Row_1);
  hv_rows.Append(hv_Row_2);
  hv_rows.Append(hv_Row_3);
  hv_columns.Clear();
  hv_columns.Append(hv_Column_1);
  hv_columns.Append(hv_Column_2);
  hv_columns.Append(hv_Column_3);

  TupleSortIndex(hv_areas, &hv_Indices);
  hv_num = hv_Indices.TupleLength();
  hv_index = HTuple(hv_Indices[hv_num-1]);

  if (0 != (hv_index==0))
  {
    hv_class = "red";
  }
  else if (0 != (hv_index==1))
  {
    hv_class = "green";
  }
  else if (0 != (hv_index==2))
  {
    hv_class = "blue";
  }

  brick_color_L = hv_class;

  hv_row_L = HTuple(hv_rows[hv_index]);
  hv_column_L = HTuple(hv_columns[hv_index]);

  Xr=hv_row_L;
  Yr=hv_column_L;

 // ROS_INFO_STREAM("Location is : "<<Xr.D()<<","<<Yr.D());
  
}

void LeftCallback(const sensor_msgs::Image::ConstPtr& msg) 
{
    //初始化halcon对象
    HObject  ho_Image;
    //获取halcon-bridge图像指针
    halcon_bridge::HalconImagePtr halcon_bridge_imagePointer = halcon_bridge::toHalconCopy(msg);
    ho_Image = *halcon_bridge_imagePointer->image;
    
    // 处理左图图像
    actionL(ho_Image);
}

void RightCallback(const sensor_msgs::Image::ConstPtr& msg) 
{
    
    //初始化halcon对象
    HObject  ho_Image;
    //获取halcon-bridge图像指针
    halcon_bridge::HalconImagePtr halcon_bridge_imagePointer = halcon_bridge::toHalconCopy(msg);
    ho_Image = *halcon_bridge_imagePointer->image;
    
    // 处理右图图像
    actionR(ho_Image);

}


//定义根据标定参数 定位三维点的函数
int stero_location(HTuple row_L, HTuple column_L, HTuple row_R, HTuple column_R)
{
   
  HTuple  hv_CameraParameters1,hv_CameraParameters2, hv_RealPose;
  HTuple  hv_X, hv_Y, hv_Z,hv_Dist;
  
  //三维定位
  try
  {
    if ((brick_color_L == brick_color_R) == 0)
    {
      ROS_WARN_STREAM("Left color isn't match Right color");
      return 1;
    }
   
    ReadCamPar("./src/bit_vision/model/campar1.dat", &hv_CameraParameters1);
    ReadCamPar("./src/bit_vision/model/campar2.dat", &hv_CameraParameters2);
    ReadPose("./src/bit_vision/model/relpose.dat", &hv_RealPose);

    IntersectLinesOfSight(hv_CameraParameters2, hv_CameraParameters2, hv_RealPose, 
    row_L, column_L, row_R, column_R, &hv_X, &hv_Y, &hv_Z, &hv_Dist);

    Brick_X = hv_X;
    Brick_Y = hv_Y;
    Brick_Z = hv_Z;

    return 0;
  }
  catch (HException &exception)
  {
    ROS_ERROR("  Error #%u in %s: %s\n", exception.ErrorCode(),
            (const char *)exception.ProcName(),
            (const char *)exception.ErrorMessage());
    return 1;
  }

}

// service 回调函数，输入参数req，输出参数res
bool GetLocateData(bit_vision::BrickLocate::Request& ,
                   bit_vision::BrickLocate::Response& res)
{
  if (stero_location(Xl,Yl,Xr,Yr)==0)   // 如果有识别结果
  {
    res.LocateData.header.stamp = ros::Time().now();
    res.LocateData.header.frame_id = "zed_link";

    res.LocateData.Flag = true;
    res.LocateData.BrickType = brick_color_L.S();
    res.LocateData.position.x = Brick_X.D();
    res.LocateData.position.y = Brick_Y.D();
    res.LocateData.position.z = Brick_Z.D();

    // 发布TF   zed_link——>target_link
    static tf::TransformBroadcaster br;
    tf::Transform transform;
    transform.setOrigin(tf::Vector3(Brick_X.D(), Brick_Y.D(), Brick_Z.D()));
    tf::Quaternion q;
    q.setRPY(0, 0, 0);
    transform.setRotation(q);
    br.sendTransform(tf::StampedTransform(transform, ros::Time::now(), "zed_link", "target_link"));

    ROS_INFO_STREAM("Brick Color is: "<<brick_color_L.S()<<"  Location is : "<<Brick_X.D()<<","<<Brick_Y.D()<<","<<Brick_Z.D());
  }
  else    // 如果没有识别结果
  {
    res.LocateData.header.stamp = ros::Time().now();
    res.LocateData.header.frame_id = "zed_link";

    res.LocateData.Flag = false;
    res.LocateData.BrickType = "NULL";
    res.LocateData.position.x = 0.0;
    res.LocateData.position.y = 0.0;
    res.LocateData.position.z = 0.0;
  }
}

int main(int argc, char *argv[])
{
  ros::init(argc, argv, "brick_locate");

  ros::NodeHandle nh; 

  // 接收zed左右相机图像
  ros::Subscriber subLeft  = nh.subscribe("/zed/zed_node/left/image_rect_color", 1, LeftCallback);
  ros::Subscriber subRight = nh.subscribe("/zed/zed_node/right/image_rect_color", 1, RightCallback);  
  // 服务-计算砖堆位置
  ros::ServiceServer service = nh.advertiseService("GetLocateData",GetLocateData);

  // 初始化左右相机定位数据
  Xl = 0;
  Yl = 0;
  Xr = 0;
  Yr = 0;

  ROS_INFO_STREAM("Ready to get brick locate info");

  ros::spin();

  return 0;
}




